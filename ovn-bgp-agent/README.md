# OVN BGP Agent Helm Chart

This Helm chart deploys the OVN BGP Agent for exposing OpenStack VMs and containers through BGP in OVN-based networking environments.

## Overview

The OVN BGP Agent enables automatic BGP route advertisement for OpenStack workloads deployed with OVN networking. It integrates with FRRouting (FRR) to establish BGP peering sessions with the underlying network infrastructure.

**Key Features:**

- **Automatic Configuration**: Zero-configuration deployment with intelligent auto-discovery of network topology
- **Flexible Deployment Modes**: Supports centralized (network nodes) and distributed (compute nodes) architectures
- **Deterministic ASN Assignment**: IP-based ASN generation ensures consistent configuration across pod restarts
- **EVPN Support**: Optional L2VPN EVPN for overlay networking scenarios
- **IPv4/IPv6 Dual-Stack**: Full support for both IPv4 and IPv6 address families
- **Multiple Driver Options**: Choose the appropriate driver for your deployment needs

## Prerequisites

- **Kubernetes**: Version 1.23 or higher
- **Helm**: Version 3.x
- **OpenStack**: Deployed with OVN networking (Neutron + OVN)
- **OVN Databases**: Accessible OVN NB and SB databases
- **Network Infrastructure**: BGP-capable switches (Leaf-Spine architecture recommended)

## Quick Start

### 1. Label Target Nodes

**For centralized deployment** (network/gateway nodes):
```bash
kubectl label nodes <network-node> openstack-network-node=enabled
```

**For distributed deployment** (compute nodes):
```bash
kubectl label nodes <compute-node> openstack-compute-node=enabled
```

### 2. Install the Chart

```bash
helm install ovn-bgp-agent ./ovn-bgp-agent \
  --namespace openstack \
  --create-namespace
```

**What happens automatically:**
1. Detects local server IP from `br-ex` interface
2. Generates local ASN based on IP address (32-bit private ASN range)
3. Discovers Leaf switch gateway IP via routing table/ARP
4. Looks up Leaf ASN from ConfigMap based on subnet
5. Configures FRR and establishes BGP session

### 3. Verify Deployment

```bash
# Check pod status
kubectl -n openstack get pods -l application=ovn-bgp-agent

# View BGP session status
kubectl -n openstack exec daemonset/ovn-bgp-agent -c frr -- \
  vtysh -c "show bgp summary"
```

## Configuration

### Basic Configuration

The simplest configuration with auto-discovery:

```yaml
bgp:
  enabled: true
  asn_mapping:
    "10.0.192.0/24": "65001"
    "10.0.193.0/24": "65002"
    "10.0.194.0/24": "65003"
```

### Peer Discovery Options

Control how the Leaf switch IP is discovered:

```yaml
bgp:
  peer_ip: ""  # Options: "", "detection", "first", "last", or explicit IP

  # "" or "detection" - Auto-detect using:
  #   1. Default route from routing table
  #   2. ARP scan of first/last subnet IP
  #   3. Fallback to first IP in subnet

  # "first" - Use first usable IP in subnet (network + 1)
  
  # "last" - Use last usable IP in subnet (broadcast - 1)
  
  # "10.0.192.1" - Explicitly specify Leaf switch IP
```

### EVPN Configuration

Enable EVPN for L2VPN overlay scenarios:

```yaml
bgp:
  enabled: true
  peer_ip: ""
  
  evpn:
    enabled: true
    rr_ip: "192.168.100.1"    # Route Reflector IP (typically Spine loopback)
    rr_asn: "65000"           # Route Reflector ASN (16-bit private range)
```

**EVPN Topology:**
```
Server ‚ÜêeBGP‚Üí Leaf:  IPv4 Unicast (underlay)
Server ‚ÜêiBGP‚Üí Spine: L2VPN EVPN (overlay)
```

### Driver Selection

Choose the appropriate driver for your use case:

```yaml
conf:
  ovn_bgp_agent:
    DEFAULT:
      driver: nb_ovn_bgp_driver  # Recommended
      
      # Available drivers:
      # - nb_ovn_bgp_driver: Uses OVN NB database (recommended, most stable)
      # - ovn_bgp_driver: Legacy driver using OVN SB database
      # - ovn_evpn_driver: EVPN support with SB database
      # - ovn_stretched_l2_bgp_driver: Stretched L2 networks
```

### Tenant Network Exposure

Configure exposure of tenant networks via BGP:

```yaml
conf:
  ovn_bgp_agent:
    DEFAULT:
      driver: nb_ovn_bgp_driver
      expose_tenant_networks: true
      expose_ipv6_gua_tenant_networks: true
      
      # Optional: Filter by OpenStack address scope
      address_scopes: "public-scope-uuid"
```

### Resource Limits

Adjust resource allocation based on deployment scale:

```yaml
pod:
  resources:
    enabled: true
    ovn_bgp_agent:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
    frr:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
```

**Recommended resource allocation by scale:**

| Deployment Size | Agent Memory | FRR Memory | Agent CPU | FRR CPU |
|----------------|--------------|------------|-----------|---------|
| Small (<100 VMs) | 256Mi | 128Mi | 200m | 100m |
| Medium (100-500) | 512Mi | 256Mi | 500m | 200m |
| Large (500-1000) | 1Gi | 512Mi | 1000m | 500m |
| Extra Large (>1000) | 2Gi | 512Mi | 2000m | 500m |

## Leaf ASN Configuration Management

### Why Configure Leaf ASN Mapping?

In a Leaf-Spine network architecture, each Leaf switch has a unique ASN. Servers need to know the correct ASN of their connected Leaf switch to establish BGP sessions. Since one Leaf switch connects to multiple servers (each with different IPs), the ASN cannot be derived from the peer IP address.

### Network Topology Example

```
         [Spine]
         AS 65000
            |
      +-----+-----+-----+
      |     |     |     |
   [Leaf1][Leaf2][Leaf3][Leaf4]
   AS65001 AS65002 AS65003 AS65004
      |     |     |     |
   Rack1  Rack2  Rack3  Rack4
10.0.192.x 193.x 194.x 195.x
```

**Mapping logic:**
- All servers in Rack1 (10.0.192.0/24) connect to Leaf-1 (AS 65001)
- All servers in Rack2 (10.0.193.0/24) connect to Leaf-2 (AS 65002)
- All servers in Rack3 (10.0.194.0/24) connect to Leaf-3 (AS 65003)

### Initial Configuration

Define the initial Leaf ASN mapping in `values.yaml`:

```yaml
bgp:
  asn_mapping:
    "10.0.192.0/24": "65001"  # Rack1 ‚Üí Leaf-1
    "10.0.193.0/24": "65002"  # Rack2 ‚Üí Leaf-2
    "10.0.194.0/24": "65003"  # Rack3 ‚Üí Leaf-3
```

On first installation, these mappings are stored in ConfigMap `ovn-bgp-agent-asn`.

### Runtime ASN Mapping Updates

#### Adding a New Rack/Leaf

**Method 1: Direct ConfigMap edit**
```bash
kubectl -n openstack edit configmap ovn-bgp-agent-asn

# Add new mapping in mapping.json:
# "10.0.195.0/24": "65004"
```

**Method 2: Using kubectl patch**
```bash
# First, get current mappings
CURRENT=$(kubectl -n openstack get configmap ovn-bgp-agent-asn -o jsonpath='{.data.mapping\.json}')

# Add new mapping
NEW=$(echo "$CURRENT" | jq '. + {"10.0.195.0/24": "65004"}')

# Apply update
kubectl -n openstack patch configmap ovn-bgp-agent-asn \
  --type merge -p "{\"data\":{\"mapping.json\":\"$NEW\"}}"
```

#### Viewing Current Mappings

```bash
kubectl -n openstack get configmap ovn-bgp-agent-asn \
  -o jsonpath='{.data.mapping\.json}' | jq .
```

**Example output:**
```json
{
  "10.0.192.0/24": "65001",
  "10.0.193.0/24": "65002",
  "10.0.194.0/24": "65003",
  "10.0.195.0/24": "65004"
}
```

### ConfigMap Update Behavior

‚ö†Ô∏è **Important Characteristics:**

1. **Initial Installation**: ConfigMap created from `values.yaml`
2. **Helm Upgrades**: Existing ConfigMap is **NOT modified** (by design)
3. **Manual Edits**: Safe to edit ConfigMap directly via `kubectl`
4. **Uninstall**: ConfigMap is automatically deleted

üîÑ **Force Regeneration from values.yaml:**
```bash
# Delete existing ConfigMap
kubectl delete configmap ovn-bgp-agent-asn -n openstack

# Helm upgrade will recreate it
helm upgrade ovn-bgp-agent ./ovn-bgp-agent --reuse-values
```

### How to Determine Leaf Switch ASN

Query your Leaf switch to find its ASN:

**Cisco:**
```bash
show bgp summary
```

**Arista:**
```bash
show ip bgp summary
```

**Cumulus Linux / FRRouting:**
```bash
vtysh -c "show bgp summary"
```

**Dell:**
```bash
show ip bgp summary
```

Look for "local AS" in the output - this is the Leaf's ASN.

## Network Architecture

### ASN Assignment Strategy

The chart uses **deterministic IP-based ASN generation** for servers:

```
ASN = 4,200,000,000 + (octet2 √ó 65,536) + (octet3 √ó 256) + octet4

Examples:
  10.0.192.111 ‚Üí AS 4200049263 (Server)
  10.0.193.111 ‚Üí AS 4200049519 (Server)
```

**Benefits:**
- ‚úÖ No manual ASN management required for servers
- ‚úÖ ASN persists across pod restarts
- ‚úÖ Collision-free (unique IPs guarantee unique ASNs)
- ‚úÖ Suitable for large-scale distributed deployments
- ‚úÖ Uses 32-bit private ASN range (4200000000-4294967294)

**Leaf ASNs** must be manually configured per the topology, typically using 16-bit private ASN range (64512-65534).

### Typical Leaf-Spine BGP Topology

```
                 [Spine]
              AS 65000 (16-bit)
                    |
         +----------+----------+
         |                     |
     [Leaf-1]              [Leaf-2]
  AS 65001 (16-bit)     AS 65002 (16-bit)
  10.0.192.1            10.0.193.1
         |                     |
    [Server-1]            [Server-2]
  AS 4200049263         AS 4200049519
  (32-bit, auto)        (32-bit, auto)
  10.0.192.111          10.0.193.111
```

**BGP Session Types:**
- Server ‚Üî Leaf: **eBGP** (IPv4 Unicast)
- Leaf ‚Üî Spine: **eBGP** (IPv4 + EVPN)
- Server ‚Üî Spine: **iBGP** (L2VPN EVPN, optional)

### Gateway Discovery Methods

The chart uses a three-tier fallback mechanism to discover the Leaf switch IP:

1. **Routing Table** (preferred):
   ```bash
   ip route show dev br-ex | grep '^default'
   ```

2. **ARP Scanning** (fallback):
   ```bash
   # Ping first and last IPs in subnet
   # Check ARP table for responses
   ```

3. **Subnet Convention** (last resort):
   ```bash
   # Assume gateway is first usable IP (network + 1)
   ```

## Deployment Modes

### Centralized Mode

Deploy only on network nodes that host OVN gateway ports (centralized router ports):

```yaml
labels:
  agent:
    node_selector_key: openstack-network-node
    node_selector_value: enabled
```

**Use cases:**
- Tenant network exposure via centralized gateways
- Traffic flows through network nodes (cr-lrp ports)

**Label nodes:**
```bash
kubectl label nodes network-node-1 openstack-network-node=enabled
kubectl label nodes network-node-2 openstack-network-node=enabled
```

### Distributed Mode

Deploy on all compute nodes:

```yaml
labels:
  agent:
    node_selector_key: openstack-compute-node
    node_selector_value: enabled
```

**Use cases:**
- Provider network VM exposure
- Floating IP (FIP) direct routing
- Traffic flows directly from compute nodes

**Label nodes:**
```bash
kubectl label nodes compute-node-1 openstack-compute-node=enabled
kubectl label nodes compute-node-2 openstack-compute-node=enabled
```

### Hybrid Mode

Deploy on both network and compute nodes using multiple DaemonSets or combined labels.

## Verification and Troubleshooting

### Check Deployment Status

```bash
# Pod status
kubectl -n openstack get pods -l application=ovn-bgp-agent

# View logs
kubectl -n openstack logs daemonset/ovn-bgp-agent -c ovn-bgp-agent
kubectl -n openstack logs daemonset/ovn-bgp-agent -c frr

# Init container logs
kubectl -n openstack logs daemonset/ovn-bgp-agent -c init-frr-config
```

### Verify BGP Sessions

```bash
# BGP summary
kubectl -n openstack exec daemonset/ovn-bgp-agent -c frr -- \
  vtysh -c "show bgp summary"

# Expected output:
# Neighbor        V  AS          MsgRcvd MsgSent   Up/Down  State
# 10.0.192.1      4  65001          123    456   01:23:45  Established
```

### Check Advertised Routes

```bash
# Routes advertised to Leaf
kubectl -n openstack exec daemonset/ovn-bgp-agent -c frr -- \
  vtysh -c "show ip bgp neighbors 10.0.192.1 advertised-routes"

# Routes received from Leaf
kubectl -n openstack exec daemonset/ovn-bgp-agent -c frr -- \
  vtysh -c "show ip bgp neighbors 10.0.192.1 routes"
```

### View FRR Configuration

```bash
kubectl -n openstack exec daemonset/ovn-bgp-agent -c frr -- \
  vtysh -c "show running-config"
```

### Common Issues

#### Issue 1: BGP Session Not Established

**Symptoms:**
```
Neighbor        V  AS      MsgRcvd MsgSent   Up/Down  State
10.0.192.1      4  65001        0       0     never    Active
```

**Diagnosis:**
```bash
# Check init container logs for configuration
kubectl -n openstack logs daemonset/ovn-bgp-agent -c init-frr-config

# Verify Leaf reachability
kubectl -n openstack exec daemonset/ovn-bgp-agent -c ovn-bgp-agent -- \
  ping -c 3 10.0.192.1

# Check FRR logs
kubectl -n openstack logs daemonset/ovn-bgp-agent -c frr
```

**Common causes:**
- Incorrect Leaf ASN in ConfigMap
- Leaf switch not configured to accept peering
- Firewall blocking TCP port 179 (BGP)
- Wrong peer IP detected

**Resolution:**
```bash
# Verify ASN mapping
kubectl -n openstack get configmap ovn-bgp-agent-asn -o yaml

# Check detected configuration
kubectl -n openstack logs daemonset/ovn-bgp-agent -c init-frr-config | \
  grep "BGP Configuration"
```

#### Issue 2: Wrong Peer IP Detected

**Symptoms:**
```
Peer (Leaf Switch):
  IPv4:         10.0.192.254
  Reachable:    no
```

**Resolution:**

Explicitly configure the correct Leaf IP:
```yaml
bgp:
  peer_ip: "10.0.192.1"  # Force specific Leaf IP
```

Then upgrade:
```bash
helm upgrade ovn-bgp-agent ./ovn-bgp-agent \
  --set bgp.peer_ip="10.0.192.1" \
  --reuse-values
```

#### Issue 3: ASN Mapping Not Found

**Symptoms:**
```
ERROR: No Leaf ASN mapping found for subnet: 10.0.195.0/24
```

**Diagnosis:**
```bash
# Check ConfigMap
kubectl -n openstack get configmap ovn-bgp-agent-asn \
  -o jsonpath='{.data.mapping\.json}' | jq .

# Check node's br-ex subnet
kubectl -n openstack exec daemonset/ovn-bgp-agent -c init-frr-config -- \
  ip -4 route show dev br-ex
```

**Resolution:**

Add the missing subnet mapping:
```bash
kubectl -n openstack edit configmap ovn-bgp-agent-asn

# Add: "10.0.195.0/24": "65004"
```

#### Issue 4: OVN Database Connection Failed

**Symptoms:**
```
ERROR: OVN NB database not accessible
```

**Diagnosis:**
```bash
# Test OVN NB connectivity
kubectl -n openstack exec daemonset/ovn-bgp-agent -c ovn-bgp-agent -- \
  ovn-nbctl --db="tcp://ovn-ovsdb-nb.openstack.svc.cluster.local:6641" show

# Check network policies
kubectl -n openstack get networkpolicies
```

**Common causes:**
- OVN databases not deployed
- Network policies blocking access
- Incorrect endpoint configuration in values.yaml

## Configuration Examples

### Example 1: Minimal Auto-Discovery Setup

```yaml
# values.yaml
bgp:
  enabled: true
  asn_mapping:
    "10.0.192.0/24": "65001"
```

### Example 2: Fixed Leaf IP with EVPN

```yaml
bgp:
  enabled: true
  peer_ip: "10.0.192.1"
  asn_mapping:
    "10.0.192.0/24": "65001"
    "10.0.193.0/24": "65002"
  
  evpn:
    enabled: true
    rr_ip: "192.168.100.1"
    rr_asn: "65000"
```

### Example 3: Tenant Network Exposure

```yaml
conf:
  ovn_bgp_agent:
    DEFAULT:
      driver: nb_ovn_bgp_driver
      expose_tenant_networks: true
      address_scopes: "public-scope-uuid"

bgp:
  enabled: true
  asn_mapping:
    "10.0.192.0/24": "65001"
```

### Example 4: Production with Resource Limits

```yaml
bgp:
  enabled: true
  asn_mapping:
    "10.0.192.0/24": "65001"
    "10.0.193.0/24": "65002"

pod:
  resources:
    enabled: true
    ovn_bgp_agent:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "2000m"
    frr:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "500m"
```

### Example 5: Multi-Rack Deployment

```yaml
bgp:
  enabled: true
  peer_ip: "first"  # Use first IP in subnet as gateway
  
  asn_mapping:
    # Data Center 1
    "10.0.192.0/24": "65001"  # DC1-Rack1 ‚Üí Leaf-1
    "10.0.193.0/24": "65002"  # DC1-Rack2 ‚Üí Leaf-2
    "10.0.194.0/24": "65003"  # DC1-Rack3 ‚Üí Leaf-3
    
    # Data Center 2
    "10.1.192.0/24": "65011"  # DC2-Rack1 ‚Üí Leaf-11
    "10.1.193.0/24": "65012"  # DC2-Rack2 ‚Üí Leaf-12

labels:
  agent:
    node_selector_key: openstack-compute-node
    node_selector_value: enabled
```

## Security Considerations

### Required Privileges

The agent requires elevated privileges to manipulate kernel networking:

```yaml
securityContext:
  privileged: true
  capabilities:
    add:
      - NET_ADMIN    # Required: kernel routing tables, ip rules
      - SYS_ADMIN    # Required: network namespaces
      - NET_RAW      # Required: ARP scanning, raw sockets
```

**Why these capabilities are needed:**
- `NET_ADMIN`: Modify kernel routing tables and rules
- `SYS_ADMIN`: Access OVS/OVN network namespaces
- `NET_RAW`: Perform ARP discovery and network diagnostics

### Network Access Requirements

The agent requires access to:

| Resource | Path/Endpoint | Access Type |
|----------|---------------|-------------|
| OVS Socket | `/run/openvswitch/db.sock` | Read |
| OVN NB | `tcp://ovn-ovsdb-nb:6641` | Read |
| OVN SB | `tcp://ovn-ovsdb-sb:6642` | Read |
| FRR Socket | `/run/frr/vtysh.sock` | Read/Write |

### Security Best Practices

1. **Namespace Isolation**: Deploy in dedicated namespace with network policies
2. **RBAC**: Use service accounts with minimal required permissions
3. **Pod Security**: Enable Pod Security Standards (restricted where possible)
4. **Audit Logging**: Enable audit logging for privileged operations
5. **Image Scanning**: Regularly scan container images for vulnerabilities

## Upgrade Strategy

### Performing an Upgrade

```bash
helm upgrade ovn-bgp-agent ./ovn-bgp-agent \
  --namespace openstack \
  --values custom-values.yaml
```

### Upgrade Behavior

- **Rolling Update**: Pods updated one at a time (maxUnavailable: 1)
- **ConfigMap Preservation**: ASN mapping ConfigMap is NOT modified during upgrades
- **BGP Session Handling**: Graceful restart minimizes traffic disruption
- **Zero Downtime**: Other nodes maintain BGP sessions during update

### Rollback

```bash
helm rollback ovn-bgp-agent -n openstack
```

## Uninstallation

### Clean Removal

```bash
helm uninstall ovn-bgp-agent --namespace openstack
```

**What gets removed:**
- ‚úÖ DaemonSet and Pods
- ‚úÖ ConfigMaps (including ASN mapping)
- ‚úÖ ServiceAccount and RBAC resources
- ‚úÖ BGP sessions (gracefully terminated)

**What persists:**
- ‚ùå Node labels (must be manually removed if needed)
- ‚ùå Kernel routing state (cleaned up automatically by agent shutdown)

### Manual Cleanup (if needed)

```bash
# Remove node labels
kubectl label nodes <node-name> openstack-network-node-
kubectl label nodes <node-name> openstack-compute-node-
```

## Advanced Topics

### BGP Timers

Default BGP timers are configured for fast convergence:

```
Keepalive: 3 seconds
Hold time: 10 seconds
Connect retry: 10 seconds
```

### Performance Characteristics

**BGP Convergence Times:**
- Single route: < 1 second
- 100 routes: < 5 seconds
- 1000 routes: < 30 seconds

**Agent Performance:**
- Route processing: ~1000 routes/second
- Memory overhead: ~1MB per 1000 routes
- CPU usage: Minimal when stable, spikes during route changes

## Contributing

We welcome contributions to improve this Helm chart!

### How to Contribute

1. Fork the [openstack-helm repository](https://github.com/openstack/openstack-helm)
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request to [OpenDev Gerrit](https://review.opendev.org)

### Development Guidelines

- Follow OpenStack Helm conventions
- Test with multiple Kubernetes versions
- Update documentation for new features
- Add examples for common use cases

## References

### Documentation

- [OVN BGP Agent Official Docs](https://docs.openstack.org/ovn-bgp-agent/latest/)
- [OpenStack Helm Documentation](https://docs.openstack.org/openstack-helm/latest/)
- [FRRouting Documentation](https://docs.frrouting.org/)

### RFCs and Standards

- [RFC 4271 - BGP-4](https://www.rfc-editor.org/rfc/rfc4271.html)
- [RFC 7938 - BGP Best Practices](https://www.rfc-editor.org/rfc/rfc7938.html)
- [RFC 7432 - BGP MPLS-Based EVPN](https://www.rfc-editor.org/rfc/rfc7432.html)
- [RFC 8365 - EVPN Overlay Solution](https://www.rfc-editor.org/rfc/rfc8365.html)

### Community

- [OpenStack Discuss Mailing List](https://lists.openstack.org/mailman3/lists/openstack-discuss.lists.openstack.org/)
- [#openstack-helm on OFTC IRC](https://oftc.net/)

## License

Licensed under the Apache License, Version 2.0. See [LICENSE](http://www.apache.org/licenses/LICENSE-2.0) for details.

---

**Version**: 0.1.0  
**App Version**: 2025.2.0  
**Maintained by**: OpenStack Helm Community